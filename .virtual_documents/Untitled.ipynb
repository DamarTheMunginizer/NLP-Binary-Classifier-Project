








#Imports
import praw
import os
#Needed to read in the varibles that are sensitive.
from dotenv import load_dotenv
load_dotenv()

import numpy as np
import pandas as pd


#Initialize PRAW and Authenticate API
reddit = praw.Reddit(
    client_id = os.getenv('client_id'),
    client_secret = os.getenv('client_secret'),
    user_agent = 'text_classifier:v1.0 (by DvisionaryS)',
    username = 'DvisionaryS',
    password = os.getenv('password')
)


# Assign a variable to the subreddits of your choosing
subreddit_1 = 'dogs'
subreddit_2 = 'personalfinance'


# Function to find post for the dataset where n: represents the number of post we are trying to pull in.
def fetch_posts(subreddit_name, total_posts=5000, batch_size=1000):
    subreddit = reddit.subreddit(subreddit_name)  # Access the subreddit
    posts = []
    after = None  # Placeholder for pagination
    fetched_post_ids = set()  # Set to track already fetched post IDs
    loops = total_posts // batch_size  # Number of loops required, adjusted to total posts

    print(f"Fetching posts from subreddit: {subreddit_name}")

    for i in range(loops):
        if i % 10 == 0: 
            print(f"Starting loop {i + 1}/{loops}")  # Print progress every 10 loops

        try:
            # Fetch posts in batches
            batch_posts = subreddit.new(limit=batch_size)
            for post in batch_posts:
                if post is not None:
                    # Skip posts that have already been fetched
                    if post.id not in fetched_post_ids:
                        posts.append({
                            'subreddit': post.subreddit.display_name,  # Export the titles I am interested in
                            'title': post.title,
                            'selftext': post.selftext,
                            'utc': post.created_utc
                        })
                        fetched_post_ids.add(post.id)  # Mark this post as fetched

            # Simulate delay to avoid rate limits
            time.sleep(60)

        except Exception as e:
            print(f"Error occurred: {e}")
            break

    return pd.DataFrame(posts)





#Read in the  data
df = pd.read_csv('./p3_data/final_df.csv')





#Import Libraries
import nltk
from nltk.tokenize import word_tokenize
import seaborn as sns
import matplotlib.pyplot as plt

from collections import Counter

from sklearn.feature_extraction.text import CountVectorizer


#View the dataset
df.shape


#Overview of data
df.head()


#View the dataset
df.info()


#Statical view of the data
df.describe()


#Check for null values
df.isnull().sum()


#Add a column for text
df['text'] = df['title'] + " " +df['selftext']


#Create a column for text_length
df['text_length'] = df['text'].apply(len)


#Create a column for the word_count
df['word_count'] = df['text'].apply(lambda x: len(word_tokenize(x)))


#Check the distribution of data
df['subreddit'].value_counts()


#Visual of distribution
plt.figure(figsize=(8, 5))
sns.countplot(data=df, x='subreddit', hue='subreddit', palette=['#1f77b4', '#ff7f0e'], legend=False)
plt.title('Class Distribution')
plt.xlabel('Subreddit')
plt.ylabel('Count')
plt.show();


#Word count distributions 
plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='word_count', hue='subreddit', kde=True, bins=30)
plt.title('Word Count Distribution by Subreddit')
plt.xlabel('Word Count')
plt.ylabel('Frequency')
plt.show()


#Top words for each subreddit
def get_top_words(texts, top_n=20):
    all_words = " ".join(texts).split()
    word_counts = Counter(all_words)
    return word_counts.most_common(top_n)

for subreddit in df['subreddit'].unique():
    subreddit_texts = df[df['subreddit'] == subreddit]['text']
    top_words = get_top_words(subreddit_texts, top_n=10)
    print(f"\nTop Words in {subreddit} Subreddit:")
    for word, count in top_words:
        print(f"{word}: {count}")


#Correlation analysis
numeric_features = df.select_dtypes(include=np.number)
if not numeric_features.empty:
    plt.figure(figsize=(10, 6))
    sns.heatmap(numeric_features.corr(), annot=True, cmap='coolwarm', fmt='.2f')
    plt.title('Correlation Matrix')
    plt.show();


#Token length analysis
df['avg_word_length'] = df['text'].apply(lambda x: np.mean([len(word) for word in word_tokenize(x)]))
plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x='subreddit', y='avg_word_length', hue='subreddit', palette='Set2')
plt.title('Average Word Length by Subreddit')
plt.xlabel('Subreddit')
plt.ylabel('Average Word Length')
plt.show()


#Extracts top n_grams
def get_top_ngrams(corpus, n=2, top_n=5):
    vectorizer = CountVectorizer(ngram_range=(n, n))
    ngrams = vectorizer.fit_transform(corpus)
    sum_ngrams = ngrams.sum(axis=0)
    ngram_counts = [(word, sum_ngrams[0, idx]) for word, idx in vectorizer.vocabulary_.items()]
    return sorted(ngram_counts, key=lambda x: x[1], reverse=True)[:top_n]

#Plots the top n_grams
def plot_top_bigrams(subreddit, bigrams, top_n=5):
    bigrams, counts = zip(*bigrams)
    plt.figure(figsize=(8, 4))
    sns.barplot(x=counts, y=bigrams, palette="coolwarm")
    plt.title(f"Top {top_n} Bigrams in {subreddit} Subreddit")
    plt.xlabel("Frequency")
    plt.ylabel("Bigrams")
    plt.show()
#Compares the subreddits in seperate charts
def compare_bigrams_separately(df, subreddit_col, text_col, n=2, top_n=5):
    subreddits = df[subreddit_col].unique()
    
    for subreddit in subreddits:
        subreddit_corpus = df[df[subreddit_col] == subreddit][text_col]
        top_bigrams = get_top_ngrams(subreddit_corpus, n=n, top_n=top_n)
        plot_top_bigrams(subreddit, top_bigrams, top_n=top_n)

# Example Usage
compare_bigrams_separately(df, subreddit_col='subreddit', text_col='text', n=2, top_n=5)








from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

import re


# Define preprocessing function
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
     # Lowercase and remove non-alphabetic characters
    text = re.sub(r'[^a-zA-Z]', ' ', text.lower())
    tokens = text.split()
    # Tokenize and lemmatize
    tokens = [lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words]
    return ' '.join(tokens)


#Apply preprocessing
df['text'] = (df['text'].apply(preprocess_text))








#Import Libraries
from sklearn.model_selection import train_test_split
from sklearn.dummy import DummyClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report


#Baseline accuracy
baseline = df['subreddit'].value_counts(normalize=True).max()
print(f'Baseline Accuracy: {baseline:.2f}')


#Set target variable
X = df['text']
y = df['subreddit'] 


#Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)


# Simulate random guessing
dummy = DummyClassifier(strategy="stratified", random_state=42)
dummy.fit(X_train, y_train)
baseline_score = dummy.score(X_test, y_test)
print(f'Baseline Accuracy (Random Guessing): {baseline_score:.2%}')


#Vectorize the text
vectorizer = TfidfVectorizer(max_features=5000)
X_train_vect = vectorizer.fit_transform(X_train)
X_test_vect = vectorizer.transform(X_test)


#Identify the two models
#Logistic Regression
model_lr = LogisticRegression()
model_lr.fit(X_train_vect, y_train)
pred_lr = model_lr.predict(X_test_vect)

#Random Forest
model_rf = RandomForestClassifier(n_estimators=100,
                                  max_depth=4,
                                  min_samples_split=200,
                                  random_state=42)
model_rf.fit(X_train_vect, y_train)
pred_rf = model_rf.predict(X_test_vect)


#Logistics Regression accuracy
lr_accuracy = model_lr.score(X_test_vect, y_test)
print(f'Logistics Regression Accuracy: {lr_accuracy:.2%}')


#View classification report
classifi = classification_report(y_test, pred_lr)
print(f'Log Regression Classification Report:\n {classifi}')


#Random Forest accuracy
rf_accuracy = model_rf.score(X_test_vect, y_test)
print(f'Random Forest Accuracy: {rf_accuracy:.2%}')


#View classification report
classi = classification_report(y_test, pred_rf)
print(f'Random Forest Classification Report:\n {classi}')





#Import the required library
from sklearn.metrics import confusion_matrix


#Run the code fetch_post(subreddit name)
#import time
sub_1 = fetch_posts(subreddit_1)
sub_2 = fetch_posts(subreddit_2)


sub_1.head()


sub_1.shape


sub_2.head()


sub_2.shape


# Assign labels for the subreddit column
sub_1['subreddit'] = 1 #Label 'dogs' as 1
sub_2['subreddit'] = 0 #Label 'personalfinance' as 0


sub_1.head()


test_df = pd.concat([sub_1, sub_2], ignore_index=True)
test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)


test_df['text'] = test_df['title'] + ' ' + test_df['selftext']


#Preprocess new data
def preprocess(text):
    if isinstance(text, str):
        return ""
     # Lowercase and remove non-alphabetic characters
        text = text.lower
        text = re.sub(r'[^a-zA-Z\s]', '', text)
        tokens = text.split()
    # Tokenize and lemmatize
        tokens = [lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words]
        return " ".join(tokens)

new_data = [preprocess(text) for text in test_df]


#Vectorize the text for model entry
new_df_vect = vectorizer.transform(test_df['text'])


#Test the data on unseen data
lr_model_test = model_lr.predict(new_df_vect)
rf_model_test = model_rf.predict(new_df_vect)


#Create a column to see what the actual subreddit was vs the preditcions of my models
test_df['logreg_predz'] = lr_model_test
test_df['rf_predz'] = rf_model_test


test_df.head()


#Eval the LogisticRegression model based on accuracy for the new data it saw
prediction = model_lr.predict(new_df_vect)
accu = accuracy_score(test_df['subreddit'], prediction)
print(f'Logistics Regression Accuracy on Imported Data: {accu:.2%}')


#Eval the RandomForest model based on accuracy for the new data it saw
predictionz = model_rf.predict(new_df_vect)
acc = accuracy_score(test_df['subreddit'], predictionz)
print(f'Random Forest Accuracy on Imported Data: {acc:.2%}')





#Give the predictions a variable
log_reg_pred = model_lr.predict(X_test_vect)
rf_pred = model_rf.predict(X_test_vect)


#Assign a variable to the ConfusionMatrix
log_cm = confusion_matrix(y_test, log_reg_pred)
rf_cm = confusion_matrix(y_test, rf_pred)





#Plot the confusion matrix
def plot_confusion_matrix(cm, title):
    plt.figure(figsize=(4, 3))
    sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', xticklabels=['subreddit[0]' , 'subreddit[1]'], yticklabels=['subreddit[0]' , 'subreddit[1]'])
    plt.title('Actual vs Predicted')
    plt.ylabel('Actual Label')
    plt.xlabel('Predicted Label')
    plt.show()

#Matrix for LogisticRegression Model
plot_confusion_matrix(log_cm, 'Logistic Regression CM') 



#Matrix for RandomForest Model
plot_confusion_matrix(rf_cm, 'Random Forest CM')















